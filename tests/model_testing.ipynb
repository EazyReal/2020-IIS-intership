{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Now) Stage 5 - Validation on ANLI/Q-Test/HAN, Experiments\n",
    "- due 9/15\n",
    "- Text Embedding\n",
    "    - to `BasicTextFieldEmbedder`\n",
    "    - `DatasetReader` to Use ``{\"transformers\": , \"pos\": ...}``\n",
    "    - `CNN Mismatched Embedder`\n",
    "- CGConv\n",
    "    - to Test\n",
    "- Deepmind naive\n",
    "    - to do\n",
    "- Graph Generator\n",
    "    - add constituent edge\n",
    "    \n",
    "# Stage 6 - Paper Fixing (due 9/19, EACL due 9/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/2020-IIS-NLU-internship/MNLI/tests'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## util\n",
    "import os\n",
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm_notebook as tqdmnb\n",
    "from tqdm import tqdm as tqdm\n",
    "import pickle\n",
    "import json \n",
    "import jsonlines as jsonl\n",
    "from collections import defaultdict\n",
    "from typing import Iterable, List, Dict, Tuple, Union\n",
    "from pathlib import Path\n",
    "## graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "# geometric\n",
    "import torch_geometric\n",
    "## nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data.data import Data\n",
    "## Stanza\n",
    "import stanza\n",
    "from stanza.models.common.doc import Document\n",
    "from stanza.pipeline.core import Pipeline\n",
    "## allennlp model\n",
    "from allennlp_models.structured_prediction.predictors.srl import SemanticRoleLabelerPredictor\n",
    "from allennlp_models.structured_prediction.predictors.biaffine_dependency_parser import BiaffineDependencyParserPredictor\n",
    "from allennlp.predictors.predictor import Predictor #\n",
    "## allennlp\n",
    "from allennlp.data import Token, Vocabulary, Instance\n",
    "from allennlp.data.fields import ListField, TextField, Field\n",
    "from allennlp.data.token_indexers import (\n",
    "    SingleIdTokenIndexer,\n",
    "    TokenCharactersIndexer,\n",
    "    ELMoTokenCharactersIndexer,\n",
    "    PretrainedTransformerIndexer,\n",
    "    PretrainedTransformerMismatchedIndexer,\n",
    ")\n",
    "from allennlp.data import DatasetReader, DataLoader, Instance, Vocabulary, PyTorchDataLoader\n",
    "from allennlp.data.tokenizers import (\n",
    "    CharacterTokenizer,\n",
    "    PretrainedTransformerTokenizer,\n",
    "    SpacyTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    ")\n",
    "from allennlp.modules.seq2vec_encoders import CnnEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n",
    "from allennlp.nn import util as nn_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config as config\n",
    "\n",
    "from src.data_git import utils as utils\n",
    "from src.data_git import reader as reader\n",
    "\n",
    "from src.models import SynNLIModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use relative by concatting pwd\n",
    "# or the cahce file name will be ..SLASH........\n",
    "bert_model = \"bert-base-uncased\"\n",
    "train_data_path = \"/work/2020-IIS-NLU-internship/MNLI/data/anli_v1.0/R1/train.jsonl\"\n",
    "validation_data_path = \"/work/2020-IIS-NLU-internship/MNLI/data/anli_v1.0/R1/dev.jsonl\"\n",
    "test_data_path = \"/work/2020-IIS-NLU-internship/MNLI/data/anli_v1.0/R1/test.jsonl\"\n",
    "cache_data_dir = \"/work/2020-IIS-NLU-internship/MNLI/data/ANLI_instance_cache/R1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from ANLI preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_indexer = {\"tokens\":PretrainedTransformerMismatchedIndexer(model_name=\"bert-base-uncased\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdr2 = reader.NLIGraphReader(input_fields=reader.config.default_fields, lazy=False, max_instances=100,\n",
    "                             token_indexers=bert_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a20143f77b4048aa6863dfbec8a3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='reading instances', max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev2 = rdr2.read(file_path=\"../data/anli_v1.0_preprocessed/R2/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38da3172999947068577294bf87a38e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='building vocab', style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(dev2, min_count={\"edge_labels\":500}, max_vocab_size={\"edge_labels\":20}, non_padded_namespaces= [\"*tags\", \"labels\"]) # need to use @@unlown@@ for edge labels\n",
    "# min_count={\"edge_labels\":150} => 58\n",
    "# min_count={\"edge_labels\":500} => 46\n",
    "# min_count={\"edge_labels\":1000} => 42\n",
    "# 1200 => 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = PyTorchDataLoader(dev2, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocabulary with namespaces:  edge_labels, Size: 12 || labels, Size: 3 || tags, Size: 30522 || Non Padded Namespaces: {'labels', '*tags'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_encoder = 300\n",
    "dim_embedder = 768\n",
    "#dim_matching = 44 # for bimpm\n",
    "dim_matching = dim_encoder # for attentive sum diff\n",
    "dim_edge = 50\n",
    "num_relations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gat', 'rgcn', 'hgt', 'cg']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph2GraphEncoder.list_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bimpm', 'att_diff']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraphPair2GraphPairEncoder.list_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global_attention']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph2VecEncoder.list_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graph_embedding_net', 'graph_matching_net']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraphPair2VecEncoder.list_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['edge_index', 'edge_attr', 'batch_id'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"g_p\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_embedder = PretrainedTransformerMismatchedEmbedder(model_name=config.TRANSFORMER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_embedder = Embedding(\n",
    "    embedding_dim = dim_edge,\n",
    "    num_embeddings = num_relations,\n",
    "    projection_dim = None,\n",
    "    weight = None,\n",
    "    padding_index = None,\n",
    "    trainable = True,\n",
    "    max_norm = None,\n",
    "    norm_type = 2.0,\n",
    "    scale_grad_by_freq = True,\n",
    "    sparse = False,\n",
    "    vocab_namespace = \"edge_labels\",\n",
    "    pretrained_file = None,\n",
    "    vocab = vocab,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_embedder(torch.zeros((3,1), dtype=torch.long)) #ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_nn = torch.nn.Linear(300, 1)\n",
    "node_nn = torch.nn.Linear(300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlobalAttention(gate_nn=Linear(in_features=300, out_features=1, bias=True), nn=Linear(in_features=300, out_features=300, bias=True))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooler = Graph2VecEncoder.by_name(\"global_attention\")(gate_nn=gate_nn, nn=node_nn)\n",
    "pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "pooler2 = deepcopy(pooler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(pooler) != id(pooler2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(pooler2.gate_nn) != id(pooler.gate_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGCNConv(300, 300, num_relations=20)\n",
      "HGTConv(in_dim=300, out_dim=300, num_types=1, num_types=20)\n",
      "CGConv(node_dim=300, edge_dim=50)\n"
     ]
    }
   ],
   "source": [
    "rgcn = Graph2GraphEncoder.by_name(\"rgcn\")(\n",
    "    in_channels=dim_encoder,\n",
    "    out_channels=dim_encoder,\n",
    "    aggr=\"add\",\n",
    "    num_relations=20,\n",
    "    root_weight=False,\n",
    "    bias=False,\n",
    ")\n",
    "print(rgcn)\n",
    "\"\"\"\n",
    "\"in_dim\" : 300\n",
    "\"out_dim\" : 300\n",
    "\"num_types\" : 10\n",
    "\"num_relations\" : 20\n",
    "\"n_heads\" : 5\n",
    "\"dropout\" : 0.2\n",
    "\"use_norm\" : true\n",
    "\"use_RTE\" : false\n",
    "\"\"\"\n",
    "ght = Graph2GraphEncoder.by_name(\"hgt\")(\n",
    "    in_dim=dim_encoder,\n",
    "    out_dim=dim_encoder,\n",
    "    num_relations=20,\n",
    "    num_types=1,\n",
    "    n_heads=5,\n",
    "    use_RTE=False,\n",
    "    use_norm=True,\n",
    ")\n",
    "print(ght)\n",
    "cg = Graph2GraphEncoder.by_name(\"cg\")(\n",
    "    channels = dim_encoder,\n",
    "    dim = dim_edge, #edge dim\n",
    "    aggr = 'add',\n",
    "    batch_norm = False,\n",
    "    bias = True\n",
    ")\n",
    "print(cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen = GraphPair2VecEncoder.by_name(\"graph_matching_net\")(convs=rgcn, num_layers=3, pooler=pooler) # this is a constructor\n",
    "#gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.bimpm_matching  import BiMpmMatching#from allennlp.common  import Params\n",
    "from allennlp.common import Params\n",
    "\n",
    "match = BiMpmMatching.from_params(\n",
    "    params = Params({\n",
    "        \"hidden_dim\" : dim_encoder,\n",
    "        \"num_perspectives\" : 10,\n",
    "        \"share_weights_between_directions\" : False,\n",
    "        \"with_full_match\" : False,\n",
    "        \"with_maxpool_match\" :  True,\n",
    "        \"with_attentive_match\" : True,\n",
    "        \"with_max_attentive_match\" : True,\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphPairMPM\n",
    "from src.modules.graph_pair2graph_pair_encoders.graph_pair_mpm import GraphPairMPM\n",
    "graph_bimpm = GraphPairMPM(bimpm=match)\n",
    "# AttentiveSumDiff\n",
    "from src.modules.graph_pair2graph_pair_encoders import AttentiveSumDiff\n",
    "from allennlp.modules import MatrixAttention\n",
    "mat_att = MatrixAttention.by_name(\"cosine\")()\n",
    "att_diff = AttentiveSumDiff(\n",
    "    att = mat_att,\n",
    "    dim = dim_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 2 different updaters\n",
    "upd = NodeUpdater.by_name(\"gru\")(input_size=dim_encoder+dim_matching, hidden_size=dim_encoder)\n",
    "upd2 = NodeUpdater.by_name(\"gru\")(input_size=dim_encoder+dim_matching, hidden_size=dim_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules import FeedForward\n",
    "from allennlp.nn import Activation\n",
    "projector = FeedForward(768, 1, 300, Activation.by_name(\"linear\")(), 0.0)\n",
    "classifier = FeedForward(300*4, 2, [300, 3], Activation.by_name(\"relu\")(), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmn = GraphPair2VecEncoder.by_name(\"graph_matching_net\")(\n",
    "    num_layers = 3,\n",
    "    convs = cg, \n",
    "    atts = att_diff,\n",
    "    updaters = [upd, upd2], # use tuple in json ok? seems not, use list instead\n",
    "    poolers =  [pooler, pooler2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#print(model._modules) # no encoder of GraphMatchingNet\n",
    "print(isinstance(gmn, torch.nn.Module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper ver text field embedder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "bte = BasicTextFieldEmbedder(\n",
    "    token_embedders = {\"tokens\": transformer_embedder}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import GraphNLIModel\n",
    "model = GraphNLIModel(\n",
    "    vocab=vocab,\n",
    "    embedder=bte,\n",
    "    edge_embedder=edge_embedder,\n",
    "    projector=projector,\n",
    "    encoder=gmn,\n",
    "    classifier=classifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probs': tensor([[0.3340, 0.3451, 0.3209],\n",
       "         [0.3302, 0.3526, 0.3172]], grad_fn=<SoftmaxBackward>),\n",
       " 'loss': tensor(1.0531, grad_fn=<NllLossBackward>)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0, 'entropy': 1.0979127883911133}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_metrics(reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/2020-IIS-NLU-internship/MNLI/tests'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../b.pkl\", \"rb\") as fo:\n",
    "    ba = pickle.load(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model(**ba, return_attention=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test GPU device can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_to_device(data, device):\n",
    "    for k in data.keys():\n",
    "        if isinstance(data[k], dict):\n",
    "            recursive_to_device(data[k], device)\n",
    "        else:\n",
    "            data[k] = data[k].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_to_device(batch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphNLIModel(\n",
       "  (embedder): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): PretrainedTransformerMismatchedEmbedder(\n",
       "      (_matched_embedder): PretrainedTransformerEmbedder(\n",
       "        (transformer_model): BertModel(\n",
       "          (embeddings): BertEmbeddings(\n",
       "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "            (position_embeddings): Embedding(512, 768)\n",
       "            (token_type_embeddings): Embedding(2, 768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (encoder): BertEncoder(\n",
       "            (layer): ModuleList(\n",
       "              (0): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (2): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (3): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (4): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (5): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (6): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (7): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (8): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (9): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (10): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (11): BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (pooler): BertPooler(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (activation): Tanh()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (edge_embedder): Embedding()\n",
       "  (projector): FeedForward(\n",
       "    (_activations): ModuleList(\n",
       "      (0): Linear()\n",
       "    )\n",
       "    (_linear_layers): ModuleList(\n",
       "      (0): Linear(in_features=768, out_features=300, bias=True)\n",
       "    )\n",
       "    (_dropout): ModuleList(\n",
       "      (0): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder): GraphMatchingNet(\n",
       "    (_convs): ModuleList(\n",
       "      (0): CGConv(node_dim=300, edge_dim=50)\n",
       "      (1): CGConv(node_dim=300, edge_dim=50)\n",
       "      (2): CGConv(node_dim=300, edge_dim=50)\n",
       "    )\n",
       "    (_atts): ModuleList(\n",
       "      (0): (CosineMatrixAttention(), dim_matching_output=300)\n",
       "      (1): (CosineMatrixAttention(), dim_matching_output=300)\n",
       "      (2): (CosineMatrixAttention(), dim_matching_output=300)\n",
       "    )\n",
       "    (_updaters): ModuleList(\n",
       "      (0): GRUNodeUpdater(\n",
       "        (_rnn): GRUCell(600, 300)\n",
       "      )\n",
       "      (1): GRUNodeUpdater(\n",
       "        (_rnn): GRUCell(600, 300)\n",
       "      )\n",
       "    )\n",
       "    (_poolers): ModuleList(\n",
       "      (0): GlobalAttention(gate_nn=Linear(in_features=300, out_features=1, bias=True), nn=Linear(in_features=300, out_features=300, bias=True))\n",
       "      (1): GlobalAttention(gate_nn=Linear(in_features=300, out_features=1, bias=True), nn=Linear(in_features=300, out_features=300, bias=True))\n",
       "    )\n",
       "  )\n",
       "  (classifier): FeedForward(\n",
       "    (_activations): ModuleList(\n",
       "      (0): ReLU()\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (_linear_layers): ModuleList(\n",
       "      (0): Linear(in_features=1200, out_features=300, bias=True)\n",
       "      (1): Linear(in_features=300, out_features=3, bias=True)\n",
       "    )\n",
       "    (_dropout): ModuleList(\n",
       "      (0): Dropout(p=0.0, inplace=False)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probs': tensor([[0.3340, 0.3451, 0.3209],\n",
       "         [0.3302, 0.3526, 0.3172]], device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " 'loss': tensor(1.0531, device='cuda:0', grad_fn=<NllLossBackward>)}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in model.to(\"cpu\").named_parameters():\n",
    "    if n[:7] == \"encoder\":\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-13 16:51:17 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2020-09-13 16:51:17 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-09-13 16:51:17 INFO: Use device: gpu\n",
      "2020-09-13 16:51:17 INFO: Loading: tokenize\n",
      "2020-09-13 16:51:17 INFO: Loading: pos\n",
      "2020-09-13 16:51:18 INFO: Loading: lemma\n",
      "2020-09-13 16:51:18 INFO: Loading: depparse\n",
      "2020-09-13 16:51:19 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from src.data_git.reader import NLIGraphReader\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "rdr_nlp = NLIGraphReader(\n",
    "        wordpiece_tokenizer = None,\n",
    "        combine_input_fields = None,\n",
    "        input_parsed  = False,\n",
    "        parser = nlp,\n",
    "        input_fields = None,\n",
    "        token_indexers = bert_indexer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.predictors import GraphNLIPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = GraphNLIPredictor(model = model, dataset_reader=rdr_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probs': [0.34745416045188904, 0.33661192655563354, 0.3159339129924774],\n",
       " 'loss': 1.1522222757339478,\n",
       " 'predicted_label': 'e'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_json(\n",
    "{\n",
    "    \"sentence1\": \"Allen is smart.\",\n",
    "    \"sentence2\" : \"Allen is stupid.\",\n",
    "    \"gold_label\": \"c\",\n",
    "})\n",
    "# to be done, need to pass nlp some where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probs': [0.333971232175827, 0.3451283872127533, 0.32090044021606445], 'loss': 1.0638387203216553, 'predicted_label': 'n'}\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict_instance(dev2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'probs': [0.33397120237350464, 0.3451283574104309, 0.32090041041374207],\n",
       "  'predicted_label': 'n'},\n",
       " {'probs': [0.33016473054885864, 0.3526087701320648, 0.31722643971443176],\n",
       "  'predicted_label': 'n'}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_batch_instance([dev2[0], dev2[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.interpret import (\n",
    "    show_sequence_attention,\n",
    "    show_matrix_attention,\n",
    "    AttentionVisualizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = AttentionVisualizer(model=model, reader=rdr_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-13 16:51:23 INFO: tokens_p are ['Allen', 'is', 'a', 'dog', '.']\n",
      "2020-09-13 16:51:23 INFO: tokens_h are ['Allen', 'is', 'a', 'cat', '.']\n",
      "2020-09-13 16:51:23 INFO: the predicted label is ['e']\n",
      "2020-09-13 16:51:23 INFO: the gold label is c\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-13 16:51:24 INFO: matrix attention at layer 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-13 16:51:24 INFO: matrix attention at layer 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-13 16:51:24 INFO: matrix attention at layer 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis.visualize_json({\n",
    "    \"sentence1\": \"Allen is a dog.\",\n",
    "    \"sentence2\": \"Allen is a cat.\",\n",
    "    \"gold_label\": \"c\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Loading + Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialization_dir = \"../param/GMN_BERT_300d_/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.Params({'classifier': {'activations': {'negative_slope': 0.2, 'type': 'leaky_relu'}, 'dropout': 0.1, 'hidden_dims': [300, 3], 'input_dim': 1200, 'num_layers': 2}, 'embedder': {'gradient_checkpointing': None, 'last_layer_only': True, 'max_length': None, 'model_name': 'bert-base-uncased', 'train_parameters': False, 'type': 'pretrained_transformer_mismatched'}, 'encoder': {'atts': {'bimpm': {'hidden_dim': 300, 'num_perspectives': 10, 'share_weights_between_directions': False, 'with_attentive_match': True, 'with_full_match': False, 'with_max_attentive_match': True, 'with_maxpool_match': True}, 'type': 'bimpm'}, 'convs': {'bias': False, 'in_channels': 300, 'num_relations': 20, 'out_channels': 300, 'root_weight': False, 'type': 'rgcn'}, 'num_layers': 3, 'pooler': {'gate_nn': {'activations': {'type': 'linear'}, 'dropout': 0, 'hidden_dims': 1, 'input_dim': 300, 'num_layers': 1}, 'nn': {'activations': {'type': 'linear'}, 'dropout': 0.1, 'hidden_dims': 300, 'input_dim': 300, 'num_layers': 1}, 'type': 'global_attention'}, 'type': 'graph_matching_net', 'updater': {'hidden_size': 300, 'input_size': 344, 'type': 'gru'}}, 'projector': {'activations': {'type': 'linear'}, 'dropout': 0, 'hidden_dims': 300, 'input_dim': 768, 'num_layers': 1}, 'type': 'graph-nli'})\n"
     ]
    }
   ],
   "source": [
    "from allennlp.common import Params\n",
    "lm_config = Params.from_file(serialization_dir+\"config.json\")\n",
    "lm_config\n",
    "print(lm_config[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "key \"updaters\" is required at location \"model.encoder.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/params.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, key, default, keep_as_dict)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'updaters'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-5deaa1d5a1c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mserialization_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialization_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mweights_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# use best by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcuda_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m ) \n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, config, serialization_dir, weights_file, cuda_device)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;31m# get_model_class method, that recurses whenever it finds a from_archive model type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextend_embedder_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_sources_mapping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(cls, config, serialization_dir, weights_file, cuda_device)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;31m# want the code to look for it, so we remove it from the parameters here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mremove_pretrained_embedding_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# Force model to cpu or gpu, as appropriate, to make sure that the embeddings are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(cls, params, constructor_to_call, constructor_to_inspect, **extras)\u001b[0m\n\u001b[1;32m    579\u001b[0m                     \u001b[0mconstructor_to_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstructor_to_call\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                     \u001b[0mconstructor_to_inspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstructor_to_inspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m                 )\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(cls, params, constructor_to_call, constructor_to_inspect, **extras)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;31m# This class has a constructor, so create kwargs for it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstructor_to_inspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconstructor_to_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mcreate_kwargs\u001b[0;34m(constructor, cls, params, **extras)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         constructed_arg = pop_and_construct_arg(\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         )\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mpop_and_construct_arg\u001b[0;34m(class_name, argument_name, annotation, default, params, **extras)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconstruct_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopped_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mconstruct_arg\u001b[0;34m(class_name, argument_name, popped_params, annotation, default, **extras)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopped_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0mpopped_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopped_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpopped_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubextras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;31m# Not optional and not supplied, that's an error!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(cls, params, constructor_to_call, constructor_to_inspect, **extras)\u001b[0m\n\u001b[1;32m    579\u001b[0m                     \u001b[0mconstructor_to_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstructor_to_call\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                     \u001b[0mconstructor_to_inspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstructor_to_inspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m                 )\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(cls, params, constructor_to_call, constructor_to_inspect, **extras)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;31m# This class has a constructor, so create kwargs for it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstructor_to_inspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconstructor_to_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mcreate_kwargs\u001b[0;34m(constructor, cls, params, **extras)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         constructed_arg = pop_and_construct_arg(\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         )\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mpop_and_construct_arg\u001b[0;34m(class_name, argument_name, annotation, default, params, **extras)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mpopped_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_NO_DEFAULT\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpopped_params\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__origin__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/allennlp/common/params.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, key, default, keep_as_dict)\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' at location \"{self.history}\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: key \"updaters\" is required at location \"model.encoder.\""
     ]
    }
   ],
   "source": [
    "from allennlp.models import Model\n",
    "#lm = Model.from_archive(\"../param\n",
    "lm = Model.load(\n",
    "    config = lm_config,\n",
    "    serialization_dir = serialization_dir,\n",
    "    weights_file = None, # use best by default\n",
    "    cuda_device = -1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-c904de65acc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlm_vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lm' is not defined"
     ]
    }
   ],
   "source": [
    "lm_vocab = lm.vocab\n",
    "lm_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-690eacbd0259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphNLIPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrdr_nlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lm' is not defined"
     ]
    }
   ],
   "source": [
    "predictor_load = GraphNLIPredictor(model = lm, dataset_reader=rdr_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att1h = lm(**batch, return_attention=True)[\"attentions\"][\"pooler2\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att1p = lm(**batch, return_attention=True)[\"attentions\"][\"pooler1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sequence_attention(str1p, att1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sequence_attention(str1h, att1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_inst(inst):\n",
    "    print(\n",
    "        inst.fields[\"tokens_p\"],\n",
    "        inst.fields[\"tokens_h\"],\n",
    "        inst.fields[\"label\"],\n",
    "        sep='\\n',\n",
    "        )\n",
    "print_inst(dev2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_load.predict_batch_instance([dev2[0], dev2[1]]) # can return label(after modify code!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two ways for model loading \n",
    "# params of config + .th\n",
    "\n",
    "\"\"\"\n",
    "components = run_config(CONFIG)\n",
    "params = components['params']\n",
    "dataset_reader = components['dataset_reader']\n",
    "vocab = components['vocab']\n",
    "model = components['model']\n",
    "\n",
    "\n",
    "original_preds = make_predictions(model, dataset_reader)\n",
    "\n",
    "# Save the model\n",
    "serialization_dir = 'model'\n",
    "config_file = os.path.join(serialization_dir, 'config.json')\n",
    "vocabulary_dir = os.path.join(serialization_dir, 'vocabulary')\n",
    "weights_file = os.path.join(serialization_dir, 'weights.th')\n",
    "\n",
    "os.makedirs(serialization_dir, exist_ok=True)\n",
    "params.to_file(config_file)\n",
    "vocab.save_to_files(vocabulary_dir)\n",
    "torch.save(model.state_dict(), weights_file)\n",
    "\n",
    "# Load the model\n",
    "loaded_params = Params.from_file(config_file)\n",
    "loaded_model = Model.load(loaded_params, serialization_dir, weights_file)\n",
    "loaded_vocab = loaded_model.vocab   # Vocabulary is loaded in Model.load()\n",
    "\n",
    "# Make sure the predictions are the same\n",
    "loaded_preds = make_predictions(loaded_model, dataset_reader)\n",
    "assert original_preds == loaded_preds\n",
    "print('predictions matched')\n",
    "\n",
    "# Create an archive file\n",
    "archive_model(serialization_dir, weights='weights.th')\n",
    "\n",
    "# Unarchive from the file\n",
    "archive = load_archive(os.path.join(serialization_dir, 'model.tar.gz'))\n",
    "\n",
    "# Make sure the predictions are the same\n",
    "archived_preds = make_predictions(archive.model, dataset_reader)\n",
    "assert original_preds == archived_preds\n",
    "print('predictions matched')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_attr=[20], edge_index=[2, 20], node_attr=[6], x=[6])\n"
     ]
    }
   ],
   "source": [
    "from src.data_git.utils import text2graph, doc2graph\n",
    "print(text2graph(\"The Big Apple is Newyork City\", nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
    "elmo_embedding = ElmoTokenEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_embedding.get_output_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from allennlp.data import Token, Vocabulary\n",
    "from allennlp.data.fields import ListField, TextField\n",
    "from allennlp.data.token_indexers import (\n",
    "    SingleIdTokenIndexer,\n",
    "    TokenCharactersIndexer,\n",
    "    ELMoTokenCharactersIndexer,\n",
    "    PretrainedTransformerIndexer,\n",
    "    PretrainedTransformerMismatchedIndexer,\n",
    ")\n",
    "from allennlp.data.tokenizers import (\n",
    "    CharacterTokenizer,\n",
    "    PretrainedTransformerTokenizer,\n",
    "    SpacyTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    ")\n",
    "from allennlp.modules.seq2vec_encoders import CnnEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n",
    "from allennlp.nn import util as nn_util\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo tokens: [This, is, some, text.]\n",
      "ELMo tensors: {'tokens': {'elmo_tokens': tensor([[259,  85, 105, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261],\n",
      "        [259, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261],\n",
      "        [259, 116, 112, 110, 102, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261],\n",
      "        [259, 117, 102, 121, 117,  47, 260, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261]]), 'mask': tensor([True, True, True, True])}}\n",
      "ELMo embedded tokens: tensor([[[ 0.0000,  0.0000, -0.0000, -0.0000, -0.8512, -0.0000, -0.4313,\n",
      "          -1.4576,  0.0000, -0.0000,  0.0271,  0.0000, -0.0000,  0.7962,\n",
      "          -0.0000, -0.1257, -0.4585,  0.9739, -1.1158, -0.2194, -1.5000,\n",
      "          -0.0000, -0.0000, -0.2449,  1.7943, -0.0000, -0.2561, -0.3259,\n",
      "          -0.0000,  0.0000, -0.0000, -0.0000],\n",
      "         [ 0.8214,  0.0000, -0.0000, -0.8952, -0.0000,  0.3791, -0.0000,\n",
      "          -0.3816,  0.6740, -0.0000,  0.2030, -0.0000, -0.0000,  0.0000,\n",
      "           0.0582,  0.3758,  0.0000,  0.0000, -0.0000, -0.6818, -0.0000,\n",
      "          -1.2560, -0.0000,  0.0000,  1.6650, -0.0000, -0.0000,  0.1510,\n",
      "          -0.0000, -0.0000, -0.0000,  0.6609],\n",
      "         [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.2793, -0.0000,\n",
      "          -0.0000,  0.1516, -0.6763,  0.0150,  0.0000, -0.7108,  0.0000,\n",
      "          -0.1125,  0.4098, -0.3095,  0.0000, -1.7565,  0.0000, -0.6707,\n",
      "          -0.0000, -0.0000,  0.2709,  0.0000, -0.0000,  0.0000,  1.8018,\n",
      "          -1.6005,  0.0000,  1.4834,  0.0000],\n",
      "         [-0.0000, -0.0000, -6.5606,  0.0000, -0.0000,  0.0000, -4.8008,\n",
      "           4.8264, -3.6068, -0.0000,  0.0000,  0.0000,  2.1829, -0.0000,\n",
      "           2.8465,  3.7315, -0.0000,  0.0000, -0.0000, -0.0000, -1.5184,\n",
      "           1.8097, -0.0000,  2.9327,  2.7400, -1.4832, -1.6098,  0.0000,\n",
      "           1.4234,  0.0000, -2.1357, -0.4789]]], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "from allennlp.data import TokenIndexer\n",
    "from src.data_git import ELMoTokenCharactersIndexerWithMask\n",
    "from src.modules import ElmoTokenEmbedderWithMask\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "token_indexer = TokenIndexer.by_name(\"elmo_characters_with_mask\")()\n",
    "vocab = Vocabulary()\n",
    "text = \"This is some text.\"\n",
    "#batch = [\"This is some text.\", \"This is some other text.\"]\n",
    "tokens = tokenizer.tokenize(text)\n",
    "#tokens = tokenizer.tokenize(text)\n",
    "print(\"ELMo tokens:\", tokens)\n",
    "text_field = TextField(tokens, {'tokens': token_indexer})\n",
    "# print(vocab)\n",
    "text_field.index(vocab=vocab)\n",
    "token_tensor = text_field.as_tensor(text_field.get_padding_lengths())\n",
    "print(\"ELMo tensors:\", token_tensor)\n",
    "\n",
    "# We're using a tiny, toy version of ELMo to demonstrate this.\n",
    "elmo_options_file = 'https://allennlp.s3.amazonaws.com/models/elmo/test_fixture/options.json'\n",
    "elmo_weight_file = 'https://allennlp.s3.amazonaws.com/models/elmo/test_fixture/lm_weights.hdf5'\n",
    "elmo_embedding = ElmoTokenEmbedderWithMask(options_file=elmo_options_file,\n",
    "                                   weight_file=elmo_weight_file)\n",
    "\n",
    "embedder = BasicTextFieldEmbedder(token_embedders={'tokens': elmo_embedding})\n",
    "\n",
    "tensor_dict = text_field.batch_tensors([token_tensor])\n",
    "embedded_tokens = embedder(tensor_dict)\n",
    "print(\"ELMo embedded tokens:\", embedded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "transformer_indexer = PretrainedTransformerMismatchedIndexer(model_name=model_name)\n",
    "transformer_embedder = PretrainedTransformerMismatchedEmbedder(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
