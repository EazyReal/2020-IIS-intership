{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import utils\n",
    "import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## util\n",
    "import os\n",
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm_notebook as tqdmnb\n",
    "from tqdm import tqdm as tqdm\n",
    "import pickle\n",
    "import json \n",
    "import jsonlines as jsonl\n",
    "from collections import defaultdict\n",
    "from typing import Iterable, List, Dict, Tuple, Union\n",
    "from pathlib import Path\n",
    "## graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "## nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data.data import Data\n",
    "## Stanza\n",
    "import stanza\n",
    "from stanza.models.common.doc import Document\n",
    "from stanza.pipeline.core import Pipeline\n",
    "## allennlp model\n",
    "from allennlp_models.structured_prediction.predictors.srl import SemanticRoleLabelerPredictor\n",
    "from allennlp_models.structured_prediction.predictors.biaffine_dependency_parser import BiaffineDependencyParserPredictor\n",
    "from allennlp.predictors.predictor import Predictor #\n",
    "## allennlp\n",
    "from allennlp.data import Token, Vocabulary, Instance\n",
    "from allennlp.data.fields import ListField, TextField, Field\n",
    "from allennlp.data.token_indexers import (\n",
    "    SingleIdTokenIndexer,\n",
    "    TokenCharactersIndexer,\n",
    "    ELMoTokenCharactersIndexer,\n",
    "    PretrainedTransformerIndexer,\n",
    "    PretrainedTransformerMismatchedIndexer,\n",
    ")\n",
    "from allennlp.data import DatasetReader, DataLoader, Instance, Vocabulary, PyTorchDataLoader\n",
    "from allennlp.data.tokenizers import (\n",
    "    CharacterTokenizer,\n",
    "    PretrainedTransformerTokenizer,\n",
    "    SpacyTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    ")\n",
    "from allennlp.modules.seq2vec_encoders import CnnEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n",
    "from allennlp.nn import util as nn_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/2020-IIS-NLU-internship/MNLI/data/MNLI_Stanza/pre_multinli_1.0_dev_mismatched.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_path = config.P_TEST_FILE\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparse_adjacency_field import SparseAdjacencyField as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del reader \n",
    "import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdr = reader.NLI_Graph_Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3019474207ab4702b9787a4043afe53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='reading instances', max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_set = rdr.read(config.P_DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e38dc1b8e6740018c208042ab3d49c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='building vocab', max=9815.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----Vocabulary Statistics----\n",
      "\n",
      "\n",
      "Top 10 most frequent tokens in namespace 'edge_labels':\n",
      "\tToken: punct\t\tFrequency: 32065\n",
      "\tToken: case\t\tFrequency: 30338\n",
      "\tToken: nsubj\t\tFrequency: 29153\n",
      "\tToken: det\t\tFrequency: 28436\n",
      "\tToken: root\t\tFrequency: 20496\n",
      "\tToken: advmod\t\tFrequency: 17098\n",
      "\tToken: amod\t\tFrequency: 16704\n",
      "\tToken: obj\t\tFrequency: 15775\n",
      "\tToken: obl\t\tFrequency: 14845\n",
      "\tToken: compound\t\tFrequency: 13444\n",
      "\n",
      "Top 10 longest tokens in namespace 'edge_labels':\n",
      "\tToken: compound:prt\t\tlength: 12\tFrequency: 1258\n",
      "\tToken: nsubj:pass\t\tlength: 10\tFrequency: 2960\n",
      "\tToken: det:predet\t\tlength: 10\tFrequency: 256\n",
      "\tToken: nmod:npmod\t\tlength: 10\tFrequency: 140\n",
      "\tToken: cc:preconj\t\tlength: 10\tFrequency: 122\n",
      "\tToken: reparandum\t\tlength: 10\tFrequency: 10\n",
      "\tToken: csubj:pass\t\tlength: 10\tFrequency: 7\n",
      "\tToken: nmod:poss\t\tlength: 9\tFrequency: 5120\n",
      "\tToken: acl:relcl\t\tlength: 9\tFrequency: 3045\n",
      "\tToken: discourse\t\tlength: 9\tFrequency: 2649\n",
      "\n",
      "Top 10 shortest tokens in namespace 'edge_labels':\n",
      "\tToken: cc\t\tlength: 2\tFrequency: 9585\n",
      "\tToken: acl\t\tlength: 3\tFrequency: 2750\n",
      "\tToken: cop\t\tlength: 3\tFrequency: 7964\n",
      "\tToken: aux\t\tlength: 3\tFrequency: 9263\n",
      "\tToken: obl\t\tlength: 3\tFrequency: 14845\n",
      "\tToken: obj\t\tlength: 3\tFrequency: 15775\n",
      "\tToken: det\t\tlength: 3\tFrequency: 28436\n",
      "\tToken: list\t\tlength: 4\tFrequency: 57\n",
      "\tToken: iobj\t\tlength: 4\tFrequency: 234\n",
      "\tToken: expl\t\tlength: 4\tFrequency: 1357\n",
      "\n",
      "Top 10 most frequent tokens in namespace 'labels':\n",
      "\tToken: entailment\t\tFrequency: 3479\n",
      "\tToken: contradiction\t\tFrequency: 3213\n",
      "\tToken: neutral\t\tFrequency: 3123\n",
      "\n",
      "Top 10 longest tokens in namespace 'labels':\n",
      "\tToken: contradiction\t\tlength: 13\tFrequency: 3213\n",
      "\tToken: entailment\t\tlength: 10\tFrequency: 3479\n",
      "\tToken: neutral\t\tlength: 7\tFrequency: 3123\n",
      "\n",
      "Top 10 shortest tokens in namespace 'labels':\n",
      "\tToken: neutral\t\tlength: 7\tFrequency: 3123\n",
      "\tToken: entailment\t\tlength: 10\tFrequency: 3479\n",
      "\tToken: contradiction\t\tlength: 13\tFrequency: 3213\n"
     ]
    }
   ],
   "source": [
    "vocab.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_loader = PyTorchDataLoader(dev_set, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dev_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['edge_index', 'edge_attr', 'batch_id'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"g_p\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_embedder = PretrainedTransformerMismatchedEmbedder(\n",
    "    model_name=config.TRANSFORMER_NAME,\n",
    "    max_length=None, # concat if over max len (512 for BERT base)\n",
    "    train_parameters=True,\n",
    "    last_layer_only=True,\n",
    "    gradient_checkpointing=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = transformer_embedder(**batch[\"tokens_p\"][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token_ids', 'mask', 'type_ids', 'wordpiece_mask', 'offsets'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens_p\"][\"tokens\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = batch[\"tokens_p\"][\"tokens\"][\"mask\"]\n",
    "mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense2sparse(input_: torch.Tensor, mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    usage: convert dense batch(for non-GNN) to sparse batch (for GNN)\n",
    "    a gather_nd method for pytorch with dimension = 3, 2\n",
    "    \n",
    "    input size = (B, batchN, D), (B,batchN)\n",
    "    ouput size = (allN, D), (allN)\n",
    "    \"\"\"\n",
    "    b, n, d = input_.size()\n",
    "    indices = mask.nonzero()\n",
    "    batch_ids = indices.T[0]\n",
    "    out = torch.stack([input_[tuple(idx)] for idx in indices])\n",
    "    return {\"data\": out, \"batch_indices\": batch_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp = dense2sparse(tp, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 768]) torch.Size([879])\n"
     ]
    }
   ],
   "source": [
    "print(stp[\"data\"].size(), stp[\"batch_indices\"].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7, 19, 30, 33, 13, 42, 15, 47, 48, 23, 38, 20, 87, 13, 96, 10, 11, 42,\n",
      "        22, 32,  9,  8, 17, 24, 13,  9, 30, 41,  6, 25, 16, 33])\n"
     ]
    }
   ],
   "source": [
    "_, seqlens = torch.unique_consecutive(stp[\"batch_indices\"], return_counts=True)\n",
    "print(seqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse2dense(input_, batch_indices):\n",
    "    \"\"\"\n",
    "    usage: convert sparse batch (for GNN) to dense batch(for non-GNN)\n",
    "    a scatter_nd method for pytorch with dimension = 3, 2\n",
    "    besure to remenber properties of original tensor\n",
    "    also besure that the input_ and batch_indices is valid\n",
    "    \n",
    "    todo: check backpro and memory issue\n",
    "    \n",
    "    input = \n",
    "        input_ (N, d), batch_indices (N)\n",
    "    output =\n",
    "        data (b, n, d), mask = (b, n)\n",
    "    \"\"\"\n",
    "    _, seqlens = torch.unique_consecutive(batch_indices, return_counts=True)\n",
    "    b = batch_indices[-1] + 1 # index + 1\n",
    "    n = torch.max(seqlens)\n",
    "    d = input_.size()[1]\n",
    "    indices_y = torch.cat([ torch.tensor(list(range(l))) for l in seqlens ], dim=0)\n",
    "    indices = torch.cat([batch_indices.unsqueeze(dim=1), indices_y.unsqueeze(dim=1)], dim=1)\n",
    "    mask = torch.full([b, n], False, dtype=bool)\n",
    "    out = torch.zeros([b, n, d], dtype=input_.dtype, device=input_.device, requires_grad=input_.requires_grad)\n",
    "    for i, index in enumerate(indices):\n",
    "        tid = tuple(index)\n",
    "        out[tid] = input_[i]\n",
    "        mask[tid] = True\n",
    "    return {\"data\": out, \"mask\": mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 96, 768]) torch.Size([32, 96])\n"
     ]
    }
   ],
   "source": [
    "print(sparse2dense(stp[\"data\"], stp[\"batch_indices\"])[\"data\"].size(),\n",
    "      sparse2dense(stp[\"data\"], stp[\"batch_indices\"])[\"mask\"].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7879, 0.0682, 0.6570, 0.7031, 0.8994],\n",
      "         [0.7991, 0.7240, 0.4886, 0.0818, 0.5140],\n",
      "         [0.5010, 0.3747, 0.6167, 0.3215, 0.2629],\n",
      "         [0.2473, 0.9370, 0.5419, 0.0911, 0.1503]],\n",
      "\n",
      "        [[0.8266, 0.3092, 0.3913, 0.4549, 0.1064],\n",
      "         [0.8491, 0.6805, 0.2992, 0.1845, 0.9280],\n",
      "         [0.5621, 0.7920, 0.0817, 0.6300, 0.4396],\n",
      "         [0.4140, 0.5625, 0.3928, 0.9321, 0.8031]],\n",
      "\n",
      "        [[0.3792, 0.4077, 0.3438, 0.0266, 0.2067],\n",
      "         [0.4379, 0.9779, 0.2881, 0.4637, 0.7458],\n",
      "         [0.9262, 0.2924, 0.1877, 0.8627, 0.9728],\n",
      "         [0.6972, 0.2883, 0.9224, 0.2346, 0.8337]]])\n",
      "tensor([[1, 0, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "emb = torch.rand(3,4,5)\n",
    "mask = torch.tensor([[1, 0, 0, 0], [1, 1, 0, 0], [1, 1, 1, 1]])\n",
    "print(emb, mask, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "semb = dense2sparse(emb, mask)[\"data\"]\n",
    "sid = dense2sparse(emb, mask)[\"batch_indices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7879, 0.0682, 0.6570, 0.7031, 0.8994],\n",
      "        [0.8266, 0.3092, 0.3913, 0.4549, 0.1064],\n",
      "        [0.8491, 0.6805, 0.2992, 0.1845, 0.9280],\n",
      "        [0.3792, 0.4077, 0.3438, 0.0266, 0.2067],\n",
      "        [0.4379, 0.9779, 0.2881, 0.4637, 0.7458],\n",
      "        [0.9262, 0.2924, 0.1877, 0.8627, 0.9728],\n",
      "        [0.6972, 0.2883, 0.9224, 0.2346, 0.8337]])\n",
      "tensor([0, 1, 1, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(semb, sid, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([[[0.7879, 0.0682, 0.6570, 0.7031, 0.8994],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.8266, 0.3092, 0.3913, 0.4549, 0.1064],\n",
       "          [0.8491, 0.6805, 0.2992, 0.1845, 0.9280],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.3792, 0.4077, 0.3438, 0.0266, 0.2067],\n",
       "          [0.4379, 0.9779, 0.2881, 0.4637, 0.7458],\n",
       "          [0.9262, 0.2924, 0.1877, 0.8627, 0.9728],\n",
       "          [0.6972, 0.2883, 0.9224, 0.2346, 0.8337]]]),\n",
       " 'mask': tensor([[ True, False, False, False],\n",
       "         [ True,  True, False, False],\n",
       "         [ True,  True,  True,  True]])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse2dense(semb, sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensor_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([[[0.7879, 0.0682, 0.6570, 0.7031, 0.8994],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.8266, 0.3092, 0.3913, 0.4549, 0.1064],\n",
       "          [0.8491, 0.6805, 0.2992, 0.1845, 0.9280],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.3792, 0.4077, 0.3438, 0.0266, 0.2067],\n",
       "          [0.4379, 0.9779, 0.2881, 0.4637, 0.7458],\n",
       "          [0.9262, 0.2924, 0.1877, 0.8627, 0.9728],\n",
       "          [0.6972, 0.2883, 0.9224, 0.2346, 0.8337]]]),\n",
       " 'mask': tensor([[ True, False, False, False],\n",
       "         [ True,  True, False, False],\n",
       "         [ True,  True,  True,  True]])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_op.sparse2dense(semb, sid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Fix, ROOT not special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_special_test = TextField([Token(\"[ROOT]\")], token_indexers={\"tokens\": PretrainedTransformerMismatchedIndexer(config.TRANSFORMER_NAME) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_special_test.index(vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': {'token_ids': [101, 1031, 7117, 1033, 102],\n",
       "  'mask': [True],\n",
       "  'type_ids': [0, 0, 0, 0, 0],\n",
       "  'offsets': [(1, 3)],\n",
       "  'wordpiece_mask': [True, True, True, True, True]}}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_special_test._indexed_tokens # this should be fixed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = PretrainedTransformerMismatchedIndexer(config.TRANSFORMER_NAME) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocabulary with namespaces:  edge_labels, Size: 46 || labels, Size: 3 || tags, Size: 30522 || Non Padded Namespaces: {'*labels', '*tags'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Use Batch to test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tokens_p', 'tokens_h', 'g_p', 'g_h', 'label'])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = SynNLIModel(vocab, transformer_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_to_device(data, device):\n",
    "    for k in data.keys():\n",
    "        if isinstance(data[k], dict):\n",
    "            recursive_to_device(data[k], device)\n",
    "        else:\n",
    "            data[k] = data[k].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 47])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_to_device(batch, device)\n",
    "md.to(device)\n",
    "print(device)\n",
    "batch[\"tokens_p\"][\"tokens\"][\"mask\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = md(**batch)[\"probs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1201, 0.1086, 0.1301],\n",
      "        [0.1039, 0.1169, 0.1118],\n",
      "        [0.1366, 0.1272, 0.1088],\n",
      "        [0.1184, 0.1310, 0.1383],\n",
      "        [0.1619, 0.1146, 0.1135],\n",
      "        [0.1051, 0.1471, 0.1239],\n",
      "        [0.1207, 0.1345, 0.1328],\n",
      "        [0.1334, 0.1200, 0.1407]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
